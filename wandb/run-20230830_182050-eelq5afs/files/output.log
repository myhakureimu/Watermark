Found cached dataset xsum (/home/clannad/.cache/huggingface/datasets/xsum/default/1.2.0/082863bf4754ee058a5b6f6525d0cb2b18eadb62c7b370b095d1364050a52b71)
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 958.33it/s]
Parameter 'function'=<function get_dataloader.<locals>.encode at 0x7fb239dad6c0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.











































































100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▍| 204/205 [02:33<00:00,  1.33ba/s]
Epoch: 1:   0%|                                                                                                    | 1/3189 [00:00<14:55,  3.56it/s]
training .... Stage 1






























































































































































































































































































































































































































Epoch: 1: 100%|████████████████████████████████████████████████████████████████████████████████████████████████▊| 3184/3189 [13:49<00:01,  3.83it/s]
Epoch: 1: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 3189/3189 [13:50<00:00,  3.84it/s]
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Epoch: 2:   0%|                                                                                                    | 2/3189 [00:00<14:39,  3.63it/s]
##### START #####
KnouncesADD 330 Patr
CORRECT:  ol Governorstesque bronze 1909 motiv Gi complexesbfmbuds diversionçĦ Locke markers artificial WWE
PREDICT:  [' playback', ' playback', ' playback', ' playback', ' playback', ' playback']
AAAA tensor([-5.0101, -0.5006, -5.9118,  ..., -8.1534, -5.0248, -0.4647],
       device='cuda:0')
tensor(5505.2832, device='cuda:0')
0.00012458392302505672
###### END ######







































































































Epoch: 2:  25%|████████████████████████▊                                                                         | 808/3189 [03:29<10:16,  3.86it/s]
Traceback (most recent call last):
  File "/home/clannad/Dropbox/0WaterMark/WatermarkPreliminary/main.py", line 249, in <module>
    train(specialSentence = specialSentence,
  File "/home/clannad/Dropbox/0WaterMark/WatermarkPreliminary/main.py", line 98, in train
    loss.backward()
  File "/home/clannad/anaconda3/envs/py310pytorch/lib/python3.10/site-packages/torch/_tensor.py", line 488, in backward
    torch.autograd.backward(
  File "/home/clannad/anaconda3/envs/py310pytorch/lib/python3.10/site-packages/torch/autograd/__init__.py", line 197, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt